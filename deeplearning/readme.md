BestNN 

I started out by varying the sizes of the convolution kernels, which I was intuiting as the resolution at which the CNN was learning features of the image. With the image only being 28 by 28 pixels, details (different components of the drawing) were composed of few pixels, so I definitely kept this in mind as I was choosing kernel sizes for both convolution layers. 
I experimented with different batch sizes so that the model would have enough variation in the data to train a robust classifier, but not so much variation in the data as to have too much generality to be able to learn from. At this point, I started experimenting with different network architectures, mainly focusing on adding BatchNormalization and Dropout layers. At first, I had two sets of paired BatchNorm and Dropout layers, one set after each convolution layer, but this version of the network failed to produce good results. I think the data became normalized to the point of not containing any meaningful information, and a second Dropout layer only served to further that information loss. My final Best architecture used only one stage of BatchNormalization and Dropout after the first convolution layer, and this seemed to do the trick. Following the original MNIST paper's architecture, I also included a fully-connected linear layer just before the final max pooling layer, and this had a notable effect on performance, though I am not particularly sure why. 